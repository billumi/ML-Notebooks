{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4394b2b7",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03afc18a",
   "metadata": {},
   "source": [
    "### Classification Evaluation Metrics\n",
    "\n",
    "This section uses a classification model example to show metrics like Accuracy, Precision, Recall, F1-Score, and the Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "303ad49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classification Metrics ---\n",
      "\n",
      "Confusion Matrix:\n",
      "[[127  18]\n",
      " [ 27 128]]\n",
      "\n",
      "Accuracy: 0.8500\n",
      "Precision: 0.8767\n",
      "Recall (Sensitivity): 0.8258\n",
      "F1-Score: 0.8505\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       145\n",
      "           1       0.88      0.83      0.85       155\n",
      "\n",
      "    accuracy                           0.85       300\n",
      "   macro avg       0.85      0.85      0.85       300\n",
      "weighted avg       0.85      0.85      0.85       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 1. Prepare Data\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 2. Train Model and Predict\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"--- Classification Metrics ---\")\n",
    "\n",
    "# A. Confusion Matrix\n",
    "# Shows the counts of correct and incorrect predictions, broken down by class.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "# Interpretation (for binary classification):\n",
    "# cm[0, 0]: True Negatives (TN)\n",
    "# cm[0, 1]: False Positives (FP)\n",
    "# cm[1, 0]: False Negatives (FN)\n",
    "# cm[1, 1]: True Positives (TP)\n",
    "\n",
    "\n",
    "# B. Core Metrics\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "# Accuracy: (TP + TN) / (TP + TN + FP + FN). Overall correctness.\n",
    "\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "# Precision: TP / (TP + FP). Proportion of positive predictions that were actually correct.\n",
    "\n",
    "print(f\"Recall (Sensitivity): {recall_score(y_test, y_pred):.4f}\")\n",
    "# Recall: TP / (TP + FN). Proportion of actual positives that were identified correctly.\n",
    "\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "# F1-Score: Harmonic mean of Precision and Recall. Good for imbalanced datasets.\n",
    "\n",
    "# C. Classification Report (combines all metrics)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0bff8b",
   "metadata": {},
   "source": [
    "### Regression Evaluation Metrics\n",
    "\n",
    "This section uses a regression model example to show metrics like Mean Squared Error, Root Mean Squared Error, and R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a45f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Regression Metrics ---\n",
      "\n",
      "Mean Absolute Error (MAE): 8.1743\n",
      "Mean Squared Error (MSE): 104.3826\n",
      "Root Mean Squared Error (RMSE): 10.2168\n",
      "R-squared (R2 Score): 0.7040\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# 1. Prepare Data\n",
    "X_reg, y_reg = make_regression(n_samples=1000, n_features=1, noise=10, random_state=42)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Train Model and Predict\n",
    "model_reg = LinearRegression()\n",
    "model_reg.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = model_reg.predict(X_test_reg)\n",
    "\n",
    "print(\"\\n--- Regression Metrics ---\")\n",
    "\n",
    "print(f\"\\nMean Absolute Error (MAE): {mean_absolute_error(y_test_reg, y_pred_reg):.4f}\")\n",
    "# MAE: Average of the absolute differences between predictions and actual values.\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test_reg, y_pred_reg):.4f}\")\n",
    "# MSE: Average of the squared differences. Penalizes large errors more heavily.\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test_reg, y_pred_reg)):.4f}\")\n",
    "# RMSE: Square root of MSE. Interpretable in the same unit as the target variable.\n",
    "\n",
    "print(f\"R-squared (R2 Score): {r2_score(y_test_reg, y_pred_reg):.4f}\")\n",
    "# R2 Score: Measures the proportion of variance in the dependent variable that is predictable\n",
    "# from the independent variables. Closer to 1 is better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
